{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_df = pd.read_csv('charity_data.csv')\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop EIN columns as we can use name as the unique identifiers\n",
    "charity_df = charity_df.drop([\"EIN\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME                      19568\n",
       "APPLICATION_TYPE             17\n",
       "AFFILIATION                   6\n",
       "CLASSIFICATION               71\n",
       "USE_CASE                      5\n",
       "ORGANIZATION                  4\n",
       "INCOME_AMT                    9\n",
       "SPECIAL_CONSIDERATIONS        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre-processing the data.  Convert all categorical values \n",
    "charity_cat = charity_df.dtypes[charity_df.dtypes ==\"object\"].index.tolist()\n",
    "charity_df[charity_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C2561        1\n",
       "C1728        1\n",
       "C1732        1\n",
       "C1236        1\n",
       "C6100        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Investigate classification values to determine if binning is required \n",
    "classification_count = charity_df['CLASSIFICATION'].value_counts()\n",
    "classification_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a58a874d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Due to the uneven distribution of CLASSIFICATION, will bucket the rare values into \"other\" category \n",
    "classification_count.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on density map, will bucket all values under 1000 into others \n",
    "\n",
    "bucket_classification = list(classification_count[classification_count<1000].index)\n",
    "for classification in bucket_classification: \n",
    "    charity_df[\"CLASSIFICATION\"] = charity_df[\"CLASSIFICATION\"].replace(classification, \"Other\")\n",
    "\n",
    "charity_df[\"CLASSIFICATION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T14        3\n",
       "T25        3\n",
       "T15        2\n",
       "T29        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check \"Application Type\" with 17 unique values to see if bucketing is needed \n",
    "application = charity_df[\"APPLICATION_TYPE\"].value_counts()\n",
    "application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since each application type might improve the training model, will leave it un-binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PARENT BOOSTER USA INC                             1260\n",
       "TOPS CLUB INC                                       765\n",
       "UNITED STATES BOWLING CONGRESS INC                  700\n",
       "WASHINGTON STATE UNIVERSITY                         492\n",
       "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC     408\n",
       "                                                   ... \n",
       "FOSTER & BANKS WALK IN FAITH FOUNDATION               1\n",
       "LOS ANGELES PENINSULA SWIMMERS INC                    1\n",
       "LACY LAKEVIEW CHAMBER OF COMMERCE                     1\n",
       "DONUM DEI                                             1\n",
       "PARENTS TAKING A STAND INC                            1\n",
       "Name: NAME, Length: 19568, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check name column\n",
    "names = charity_df.NAME.value_counts()\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a58924ed0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                                                                 25987\n",
       "PARENT BOOSTER USA INC                                                 1260\n",
       "TOPS CLUB INC                                                           765\n",
       "UNITED STATES BOWLING CONGRESS INC                                      700\n",
       "WASHINGTON STATE UNIVERSITY                                             492\n",
       "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                         408\n",
       "PTA TEXAS CONGRESS                                                      368\n",
       "SOROPTIMIST INTERNATIONAL OF THE AMERICAS INC                           331\n",
       "ALPHA PHI SIGMA                                                         313\n",
       "TOASTMASTERS INTERNATIONAL                                              293\n",
       "MOST WORSHIPFUL STRINGER FREE AND ACCEPTED MASONS                       287\n",
       "LITTLE LEAGUE BASEBALL INC                                              277\n",
       "INTERNATIONAL ASSOCIATION OF LIONS CLUBS                                266\n",
       "MOMS CLUB                                                               210\n",
       "INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL & TRANSPORTATION      206\n",
       "AMERICAN ASSOCIATION OF UNIVERSITY WOMEN                                197\n",
       "FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA                    166\n",
       "KNIGHTS OF COLUMBUS                                                     158\n",
       "HABITAT FOR HUMANITY INTERNATIONAL INC                                  154\n",
       "TENNESSEE ORDER OF THE EASTERN STAR                                     151\n",
       "VETERANS OF FOREIGN WARS OF THE UNITED STATES AUXILIARY                 144\n",
       "PTA UTAH CONGRESS                                                       140\n",
       "THE UNITED STATES PONY CLUBS INC                                        136\n",
       "CIVITAN INTERNATIONAL                                                   131\n",
       "SIGMA BETA DELTA INC                                                    127\n",
       "HONOR SOCIETY OF PHI KAPPA PHI                                          107\n",
       "MONTANA 4-H FOUNDATION INC                                              107\n",
       "WASHINGTON STATE GRANGE                                                 106\n",
       "UNIVERSITY OF WYOMING                                                   105\n",
       "DEMOLAY INTERNATIONAL                                                   104\n",
       "SERTOMA INC                                                             103\n",
       "Name: NAME, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bucket names \n",
    "bucket_names = list(names[names<100].index)\n",
    "for name in bucket_names: \n",
    "    charity_df[\"NAME\"] = charity_df[\"NAME\"].replace(name, \"Other\")\n",
    "\n",
    "charity_df[\"NAME\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_ALPHA PHI SIGMA</th>\n",
       "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
       "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
       "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
       "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
       "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
       "      <th>NAME_HABITAT FOR HUMANITY INTERNATIONAL INC</th>\n",
       "      <th>NAME_HONOR SOCIETY OF PHI KAPPA PHI</th>\n",
       "      <th>NAME_INTERNATIONAL ASSOCIATION OF LIONS CLUBS</th>\n",
       "      <th>NAME_INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL &amp; TRANSPORTATION</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME_ALPHA PHI SIGMA  NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC  \\\n",
       "0                   0.0                                                0.0      \n",
       "1                   0.0                                                0.0      \n",
       "2                   0.0                                                0.0      \n",
       "3                   0.0                                                0.0      \n",
       "4                   0.0                                                0.0      \n",
       "\n",
       "   NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN  NAME_CIVITAN INTERNATIONAL  \\\n",
       "0                                            0.0                         0.0   \n",
       "1                                            0.0                         0.0   \n",
       "2                                            0.0                         0.0   \n",
       "3                                            0.0                         0.0   \n",
       "4                                            0.0                         0.0   \n",
       "\n",
       "   NAME_DEMOLAY INTERNATIONAL  \\\n",
       "0                         0.0   \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "\n",
       "   NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA  \\\n",
       "0                                                0.0           \n",
       "1                                                0.0           \n",
       "2                                                0.0           \n",
       "3                                                0.0           \n",
       "4                                                0.0           \n",
       "\n",
       "   NAME_HABITAT FOR HUMANITY INTERNATIONAL INC  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   NAME_HONOR SOCIETY OF PHI KAPPA PHI  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   NAME_INTERNATIONAL ASSOCIATION OF LIONS CLUBS  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   NAME_INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL & TRANSPORTATION  \\\n",
       "0                                                0.0                         \n",
       "1                                                0.0                         \n",
       "2                                                0.0                         \n",
       "3                                                0.0                         \n",
       "4                                                0.0                         \n",
       "\n",
       "   ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0  ...                0.0                     0.0                       0.0   \n",
       "1  ...                1.0                     0.0                       0.0   \n",
       "2  ...                0.0                     0.0                       0.0   \n",
       "3  ...                0.0                     1.0                       0.0   \n",
       "4  ...                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode all categorical values \n",
    "enc = OneHotEncoder(sparse = False)\n",
    "encode_df = pd.DataFrame(enc.fit_transform(charity_df[charity_cat]))\n",
    "encode_df.columns = enc.get_feature_names(charity_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the encoded dataframe back into main dataframe, drop the converted columns \n",
    "charity_df = charity_df.merge(encode_df, left_index = True, right_index = True)\n",
    "charity_df = charity_df.drop(charity_cat, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training and testing data. The target is to predict if the money is used effectively, so \"IS_SUCESSFUL\"\n",
    "#will be the target \n",
    "\n",
    "y = charity_df['IS_SUCCESSFUL'].values\n",
    "X=charity_df.drop(\"IS_SUCCESSFUL\", axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build neural network. The total number of rows is over 36,000, with 36 input dimensions.  Because of the large number of \n",
    "#input dimensions, I will build a neural network with 2 layers, first layer with 10 units and second with 8\n",
    "\n",
    "input_features = len(X_train_scaled[0])\n",
    "nodes_layer1 = 10\n",
    "nodes_layer2 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units = nodes_layer1, input_dim = input_features, activation = \"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units = nodes_layer2, activation = \"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units =1, activation = \"sigmoid\"))\n",
    "nn.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 3s 117us/sample - loss: 0.5514 - accuracy: 0.7112\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5078 - accuracy: 0.7500\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5020 - accuracy: 0.7535\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4987 - accuracy: 0.7554\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4952 - accuracy: 0.7546\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4926 - accuracy: 0.7558\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4911 - accuracy: 0.7573\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4899 - accuracy: 0.7577\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.4890 - accuracy: 0.7567\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4885 - accuracy: 0.7566\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4881 - accuracy: 0.7568\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4877 - accuracy: 0.7579\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4868 - accuracy: 0.7591\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4869 - accuracy: 0.7575\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4864 - accuracy: 0.7579\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4862 - accuracy: 0.7589\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.4852 - accuracy: 0.7587\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.4851 - accuracy: 0.7588\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4851 - accuracy: 0.7591\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4844 - accuracy: 0.7591\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4845 - accuracy: 0.7595\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4840 - accuracy: 0.7599\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.4842 - accuracy: 0.7596\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4845 - accuracy: 0.7593\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4840 - accuracy: 0.7604\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4838 - accuracy: 0.7601\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4837 - accuracy: 0.7591\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4836 - accuracy: 0.7605\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4833 - accuracy: 0.7603\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4837 - accuracy: 0.7610\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4834 - accuracy: 0.7608\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4831 - accuracy: 0.7605\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4834 - accuracy: 0.7606\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4828 - accuracy: 0.7611\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4827 - accuracy: 0.7613\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4828 - accuracy: 0.7596\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4829 - accuracy: 0.7605\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4825 - accuracy: 0.7603\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4828 - accuracy: 0.7612\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4826 - accuracy: 0.7615\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4824 - accuracy: 0.7613\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4823 - accuracy: 0.7624\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4822 - accuracy: 0.7612\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4822 - accuracy: 0.7613\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4816 - accuracy: 0.7615\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4826 - accuracy: 0.7613\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4822 - accuracy: 0.7619\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.4819 - accuracy: 0.7624\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4821 - accuracy: 0.7614\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4818 - accuracy: 0.7631\n",
      "8575/1 - 0s - loss: 0.5087 - accuracy: 0.7528\n",
      "Loss: 0.4974880984295214, Accuracy: 0.7527697086334229\n"
     ]
    }
   ],
   "source": [
    "#train the model \n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs = 50)\n",
    "#evaluate model accuracy\n",
    "model_loss, model_accuracy =nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy is just above 75%, so attempt to see if any optimization can be achieved. \n",
    "#Optimization: 1) re-look at dataset to remove any noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000       25398\n",
       "10478          3\n",
       "15583          3\n",
       "6725           3\n",
       "63981          3\n",
       "           ...  \n",
       "772556         1\n",
       "70103          1\n",
       "27096          1\n",
       "25049          1\n",
       "1138700        1\n",
       "Name: ASK_AMT, Length: 8747, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at outliers for the ASK_AMT variable\n",
    "amount = X.ASK_AMT.value_counts()\n",
    "amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8747"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ASK_AMT.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000     25398\n",
       "Other     8901\n",
       "Name: ASK_AMT, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Given the variation in this variable with over 8000 unique values, I'll bucket the value so that all amounts not equal to 5000 will be grouped together \n",
    "\n",
    "bucket_amount = list(amount[amount<25000].index)\n",
    "for amt in bucket_amount: \n",
    "    X[\"ASK_AMT\"] = X['ASK_AMT'].replace(amt, \"Other\")\n",
    "X.ASK_AMT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT_5000</th>\n",
       "      <th>ASK_AMT_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT_5000  ASK_AMT_Other\n",
       "0           1.0            0.0\n",
       "1           0.0            1.0\n",
       "2           1.0            0.0\n",
       "3           0.0            1.0\n",
       "4           0.0            1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"ASK_AMT\"] = X[\"ASK_AMT\"].astype(str)\n",
    "encode_amount = pd.DataFrame(enc.fit_transform(X[\"ASK_AMT\"].values.reshape(-1,1)))\n",
    "encode_amount.columns = enc.get_feature_names(['ASK_AMT'])\n",
    "encode_amount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.merge(encode_amount, left_index = True, right_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>NAME_ALPHA PHI SIGMA</th>\n",
       "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
       "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
       "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
       "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
       "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
       "      <th>NAME_HABITAT FOR HUMANITY INTERNATIONAL INC</th>\n",
       "      <th>NAME_HONOR SOCIETY OF PHI KAPPA PHI</th>\n",
       "      <th>NAME_INTERNATIONAL ASSOCIATION OF LIONS CLUBS</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "      <th>ASK_AMT_5000</th>\n",
       "      <th>ASK_AMT_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  NAME_ALPHA PHI SIGMA  \\\n",
       "0       1                   0.0   \n",
       "1       1                   0.0   \n",
       "2       1                   0.0   \n",
       "3       1                   0.0   \n",
       "4       1                   0.0   \n",
       "\n",
       "   NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN  NAME_CIVITAN INTERNATIONAL  \\\n",
       "0                                            0.0                         0.0   \n",
       "1                                            0.0                         0.0   \n",
       "2                                            0.0                         0.0   \n",
       "3                                            0.0                         0.0   \n",
       "4                                            0.0                         0.0   \n",
       "\n",
       "   NAME_DEMOLAY INTERNATIONAL  \\\n",
       "0                         0.0   \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "\n",
       "   NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA  \\\n",
       "0                                                0.0           \n",
       "1                                                0.0           \n",
       "2                                                0.0           \n",
       "3                                                0.0           \n",
       "4                                                0.0           \n",
       "\n",
       "   NAME_HABITAT FOR HUMANITY INTERNATIONAL INC  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   NAME_HONOR SOCIETY OF PHI KAPPA PHI  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   NAME_INTERNATIONAL ASSOCIATION OF LIONS CLUBS  ...  \\\n",
       "0                                            0.0  ...   \n",
       "1                                            0.0  ...   \n",
       "2                                            0.0  ...   \n",
       "3                                            0.0  ...   \n",
       "4                                            0.0  ...   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  ASK_AMT_5000  \\\n",
       "0                       1.0                       0.0           1.0   \n",
       "1                       1.0                       0.0           0.0   \n",
       "2                       1.0                       0.0           1.0   \n",
       "3                       1.0                       0.0           0.0   \n",
       "4                       1.0                       0.0           0.0   \n",
       "\n",
       "   ASK_AMT_Other  \n",
       "0            0.0  \n",
       "1            1.0  \n",
       "2            0.0  \n",
       "3            1.0  \n",
       "4            1.0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X.drop('ASK_AMT',1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-split, re-scale, and re-build the model with new dataset \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42)\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = len(X_train_scaled[0])\n",
    "nodes_layer1 = 10\n",
    "nodes_layer2 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units = nodes_layer1, input_dim = input_features, activation = \"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units = nodes_layer2, activation = \"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units =1, activation = \"sigmoid\"))\n",
    "nn.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.5549 - accuracy: 0.7166\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.5039 - accuracy: 0.7493s - los\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.4972 - accuracy: 0.7531\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4942 - accuracy: 0.7552\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4922 - accuracy: 0.7567\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4919 - accuracy: 0.7559\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4910 - accuracy: 0.7574\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4901 - accuracy: 0.7570\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4899 - accuracy: 0.7587\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4893 - accuracy: 0.7582\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4884 - accuracy: 0.7586\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4881 - accuracy: 0.7582\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4873 - accuracy: 0.7586\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4866 - accuracy: 0.7589\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4867 - accuracy: 0.7602\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4860 - accuracy: 0.7601\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4853 - accuracy: 0.7603\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.4834 - accuracy: 0.7606\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.4832 - accuracy: 0.7606\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.4832 - accuracy: 0.7598s - loss: 0.4823 - accura\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.4829 - accuracy: 0.7610\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4825 - accuracy: 0.7607\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4824 - accuracy: 0.7596\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.4820 - accuracy: 0.7624\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4822 - accuracy: 0.7613\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4818 - accuracy: 0.7610\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4818 - accuracy: 0.7611\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.4815 - accuracy: 0.7611\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4814 - accuracy: 0.7602\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4811 - accuracy: 0.7607\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4810 - accuracy: 0.7619\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4808 - accuracy: 0.7617\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4807 - accuracy: 0.7612\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4810 - accuracy: 0.7612\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4812 - accuracy: 0.7617\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4805 - accuracy: 0.7619\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4807 - accuracy: 0.7614\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4802 - accuracy: 0.7619\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.4804 - accuracy: 0.7621\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4805 - accuracy: 0.7618\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4805 - accuracy: 0.7624\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4806 - accuracy: 0.7622\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4802 - accuracy: 0.7616\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4804 - accuracy: 0.7616\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4802 - accuracy: 0.7616\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.4799 - accuracy: 0.7629\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.4798 - accuracy: 0.7631\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4799 - accuracy: 0.7635\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.4799 - accuracy: 0.7619\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.4799 - accuracy: 0.7619\n",
      "8575/1 - 1s - loss: 0.4991 - accuracy: 0.7549\n",
      "Loss: 0.49442450287738277, Accuracy: 0.7548688054084778\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn.fit(X_train_scaled, y_train, epochs = 50)\n",
    "#evaluate model accuracy\n",
    "model_loss, model_accuracy =nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 0.5455 - accuracy: 0.7226\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5013 - accuracy: 0.7525\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4957 - accuracy: 0.7545\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4928 - accuracy: 0.7587\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4911 - accuracy: 0.7598\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4896 - accuracy: 0.7586\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4887 - accuracy: 0.7592\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.4879 - accuracy: 0.7598\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4872 - accuracy: 0.7600\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4864 - accuracy: 0.7608\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4859 - accuracy: 0.7609\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4853 - accuracy: 0.7602\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4850 - accuracy: 0.7622\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4847 - accuracy: 0.7617\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4841 - accuracy: 0.7623\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4840 - accuracy: 0.7619\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4837 - accuracy: 0.7628\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4829 - accuracy: 0.7639\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4830 - accuracy: 0.7638\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4825 - accuracy: 0.7611\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4826 - accuracy: 0.7631\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4819 - accuracy: 0.7642\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4816 - accuracy: 0.7640\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4813 - accuracy: 0.7630\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4814 - accuracy: 0.7621\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 3s 97us/sample - loss: 0.4815 - accuracy: 0.7619\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4810 - accuracy: 0.7635\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4808 - accuracy: 0.7631\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4805 - accuracy: 0.7610\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4802 - accuracy: 0.7643\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4806 - accuracy: 0.7633\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.4803 - accuracy: 0.7644\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4798 - accuracy: 0.7662\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4800 - accuracy: 0.7640\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4799 - accuracy: 0.7633\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4793 - accuracy: 0.7644\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4795 - accuracy: 0.7640\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4795 - accuracy: 0.7636\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4791 - accuracy: 0.7644\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4793 - accuracy: 0.7642\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4790 - accuracy: 0.7639\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4791 - accuracy: 0.7646\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.4787 - accuracy: 0.7649\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4786 - accuracy: 0.7649\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4785 - accuracy: 0.7650\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4785 - accuracy: 0.7638\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4784 - accuracy: 0.7639\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4782 - accuracy: 0.7645s - loss: 0.4780 - accuracy: 0.76\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.4781 - accuracy: 0.7639\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4781 - accuracy: 0.7657\n",
      "8575/1 - 1s - loss: 0.4966 - accuracy: 0.7566\n",
      "Loss: 0.49503976945279293, Accuracy: 0.756618082523346\n"
     ]
    }
   ],
   "source": [
    "#Very slight improvement.  \n",
    "#Optimization 2: Add extra neurons to layer 1\n",
    "\n",
    "new_nodes_layer1 = 20\n",
    "nodes_layer2 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units = new_nodes_layer1, input_dim = input_features, activation = \"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units = nodes_layer2, activation = \"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units =1, activation = \"sigmoid\"))\n",
    "nn.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs = 50)\n",
    "#evaluate model accuracy\n",
    "model_loss, model_accuracy =nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 3s 109us/sample - loss: 0.5397 - accuracy: 0.7273\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4976 - accuracy: 0.7544\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4928 - accuracy: 0.7580\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4906 - accuracy: 0.7568\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4885 - accuracy: 0.7590\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4874 - accuracy: 0.7591\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4867 - accuracy: 0.7585\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4862 - accuracy: 0.7581\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4857 - accuracy: 0.7598\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4849 - accuracy: 0.7598\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4840 - accuracy: 0.7600\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4833 - accuracy: 0.7605\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4833 - accuracy: 0.7593\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4826 - accuracy: 0.7611\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4830 - accuracy: 0.7609\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4818 - accuracy: 0.7619\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4816 - accuracy: 0.7613\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4817 - accuracy: 0.7630\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4806 - accuracy: 0.7631\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4808 - accuracy: 0.7625\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4808 - accuracy: 0.7619\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4805 - accuracy: 0.7633\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4801 - accuracy: 0.7631\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4799 - accuracy: 0.7630\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4796 - accuracy: 0.7626\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4796 - accuracy: 0.7629\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4790 - accuracy: 0.7632\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4789 - accuracy: 0.7647\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4792 - accuracy: 0.7635\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4787 - accuracy: 0.7625\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.4789 - accuracy: 0.7634\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4783 - accuracy: 0.7650\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4779 - accuracy: 0.7642\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.4778 - accuracy: 0.7649\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4777 - accuracy: 0.7641\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4774 - accuracy: 0.7650\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4779 - accuracy: 0.7642\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4775 - accuracy: 0.7636\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4768 - accuracy: 0.7638\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4768 - accuracy: 0.7648\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.4771 - accuracy: 0.7642\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4767 - accuracy: 0.7653\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4760 - accuracy: 0.7667s - loss: 0\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.4766 - accuracy: 0.7644\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.4761 - accuracy: 0.7661\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.4762 - accuracy: 0.7654\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4765 - accuracy: 0.7644\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4758 - accuracy: 0.7659\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4761 - accuracy: 0.7659\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4756 - accuracy: 0.7650\n",
      "8575/1 - 0s - loss: 0.5006 - accuracy: 0.7514\n",
      "Loss: 0.4984718167747075, Accuracy: 0.7513702511787415\n"
     ]
    }
   ],
   "source": [
    "#SLight improvement\n",
    "#Optimization 3: Try adding more neurons to second layer \n",
    "\n",
    "new_nodes_layer1 = 20\n",
    "new_nodes_layer2 = 12\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units = new_nodes_layer1, input_dim = input_features, activation = \"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units = new_nodes_layer2, activation = \"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units =1, activation = \"sigmoid\"))\n",
    "nn.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs = 50)\n",
    "#evaluate model accuracy\n",
    "model_loss, model_accuracy =nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.5248 - accuracy: 0.7342\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.4973 - accuracy: 0.7514\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.4947 - accuracy: 0.7537\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.4919 - accuracy: 0.7555\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.4909 - accuracy: 0.7568\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.4899 - accuracy: 0.7568\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.4891 - accuracy: 0.7584\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4883 - accuracy: 0.7575\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4879 - accuracy: 0.7598\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4874 - accuracy: 0.7580\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4872 - accuracy: 0.7589\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4867 - accuracy: 0.7585\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4863 - accuracy: 0.7587\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4860 - accuracy: 0.7620\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4857 - accuracy: 0.7588\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4852 - accuracy: 0.7593\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4853 - accuracy: 0.7600\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4849 - accuracy: 0.7594\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 76us/sample - loss: 0.4847 - accuracy: 0.7607\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4845 - accuracy: 0.7596\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 82us/sample - loss: 0.4841 - accuracy: 0.7599\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.4844 - accuracy: 0.7623\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.4840 - accuracy: 0.7596\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.4834 - accuracy: 0.7605\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.4835 - accuracy: 0.7596\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4832 - accuracy: 0.7615\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4834 - accuracy: 0.7614\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.4833 - accuracy: 0.7608\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.4830 - accuracy: 0.7616\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.4829 - accuracy: 0.7605s -\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.4827 - accuracy: 0.7615\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.4819 - accuracy: 0.7613\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4824 - accuracy: 0.7615\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.4821 - accuracy: 0.7627\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4821 - accuracy: 0.7629\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4822 - accuracy: 0.7617\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4821 - accuracy: 0.7617\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.4818 - accuracy: 0.7613\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.4818 - accuracy: 0.7624\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4817 - accuracy: 0.7631\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 72us/sample - loss: 0.4813 - accuracy: 0.7626\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4814 - accuracy: 0.7628\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 2s 71us/sample - loss: 0.4811 - accuracy: 0.7633\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4812 - accuracy: 0.7618s - loss: 0.4799 - accuracy: \n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.4812 - accuracy: 0.7624\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4809 - accuracy: 0.7613\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4811 - accuracy: 0.7617\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.4812 - accuracy: 0.7633\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.4806 - accuracy: 0.7642\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 74us/sample - loss: 0.4807 - accuracy: 0.7628\n",
      "8575/1 - 1s - loss: 0.4937 - accuracy: 0.7520\n",
      "Loss: 0.49407838192695086, Accuracy: 0.7519533634185791\n"
     ]
    }
   ],
   "source": [
    "#Performance dropped\n",
    "#attempt a different activation method with previous nodes\n",
    "\n",
    "new_nodes_layer1 = 20\n",
    "nodes_layer2 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units = new_nodes_layer1, input_dim = input_features, activation = tf.keras.layers.LeakyReLU(alpha=0.3)))\n",
    "nn.add(tf.keras.layers.Dense(units = nodes_layer2, activation = tf.keras.layers.LeakyReLU(alpha=0.3)))\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units =1, activation = \"sigmoid\"))\n",
    "nn.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs = 50)\n",
    "#evaluate model accuracy\n",
    "model_loss, model_accuracy =nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model performance dropped.  \n",
    "\n",
    "#Plot the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4e011410>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there is very little marginal improvement in the model with each epoch, there is no reason to believe that training the model with \n",
    "#more epochs would drastically improve the model \n",
    "\n",
    "#Hence I will not attempt to further optimize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest predictive accuracy: 0.754\n"
     ]
    }
   ],
   "source": [
    "#Comparison with Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators = 128, random_state = 78)\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\"Random forest predictive accuracy: {accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
